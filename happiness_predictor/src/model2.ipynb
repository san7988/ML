{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.stem.snowball import SnowballStemmer, PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38932, 5)\n",
      "(29404, 4)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\".\\\\data\\\\train.csv\", encoding='utf=8')\n",
    "test = pd.read_csv(\".\\\\data\\\\test.csv\", encoding='utf=8')\n",
    "print train.shape\n",
    "print test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38932\n"
     ]
    }
   ],
   "source": [
    "train_len = train.shape[0]\n",
    "print train_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38932, 4)\n",
      "Index([u'User_ID', u'Description', u'Browser_Used', u'Device_Used'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train_labels = train[\"Is_Response\"]\n",
    "train.drop(\"Is_Response\", axis=1, inplace=True)\n",
    "print train.shape\n",
    "print train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68336, 4)\n"
     ]
    }
   ],
   "source": [
    "total_data = train.append(test)\n",
    "print total_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Chrome' u'Edge' u'Firefox' u'Google Chrome' u'IE' u'Internet Explorer'\n",
      " u'InternetExplorer' u'Mozilla' u'Mozilla Firefox' u'Opera' u'Safari']\n",
      "[u'Desktop' u'Mobile' u'Tablet']\n"
     ]
    }
   ],
   "source": [
    "cols = ['Browser_Used', 'Device_Used']\n",
    "for c in cols:\n",
    "    lb = LabelEncoder()\n",
    "    total_data[c] = lb.fit_transform(total_data[c])\n",
    "    print lb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# stemmer = PorterStemmer()\n",
    "# # stop_words = set(stopwords.words('english'))\n",
    "# for i,r in total_data.iterrows():\n",
    "#     wt = word_tokenize(r[1])\n",
    "#     filtered_desc = []\n",
    "#     for w in wt:\n",
    "#         filtered_desc.append(stemmer.stem(w))\n",
    "#     print i,\n",
    "#     total_data.loc[i,\"Description\"] = \" \".join(filtered_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_df = pd.read_csv(\"stemmed.csv\", encoding='utf=8')\n",
    "total_data[\"Description\"] = stemmed_df[\"Description\"]\n",
    "# total_data.to_csv(\"stemmed.csv\", index=False,encoding ='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\sasnjeev\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38932, 3)\n",
      "(29404, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\sasnjeev\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "train_new = total_data.iloc[:train_len,:]\n",
    "submission = total_data.iloc[train_len:,:]\n",
    "submission_user_id = submission[\"User_ID\"]\n",
    "train_new.drop(\"User_ID\", axis=1, inplace=True)\n",
    "submission.drop(\"User_ID\", axis=1, inplace=True)\n",
    "print train_new.shape\n",
    "print submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38932, 3)\n"
     ]
    }
   ],
   "source": [
    "print train_new.shape\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_new,train_labels, test_size=0.33, random_state=2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26084, 3)\n",
      "Index([u'Description', u'Browser_Used', u'Device_Used'], dtype='object')\n",
      "(12848, 3)\n",
      "Index([u'Description', u'Browser_Used', u'Device_Used'], dtype='object')\n",
      "(26084L,)\n",
      "(12848L,)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print X_train.columns\n",
    "print X_test.shape\n",
    "print X_test.columns\n",
    "print y_train.shape\n",
    "# print y_train.columns\n",
    "print y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=1000, min_df=5,\n",
       "        ngram_range=(1, 2), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words='english', min_df=5, ngram_range=(1,2), max_features=1000)\n",
    "cv.fit(X_train.Description.values.tolist()+X_test.Description.values.tolist()+submission.Description.values.tolist())\n",
    "tfidf = TfidfVectorizer(stop_words='english', min_df=5, ngram_range=(1,2), max_features=1000)\n",
    "tfidf.fit(X_train.Description.values.tolist()+X_test.Description.values.tolist()+submission.Description.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_desc_vec = cv.transform(X_train.Description.values.tolist())\n",
    "X_test_desc_vec = cv.transform(X_test.Description.values.tolist())\n",
    "submission_desc_vec = cv.transform(submission.Description.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_desc_tfidf = tfidf.transform(X_train.Description.values.tolist())\n",
    "X_test_desc_tfidf = tfidf.transform(X_test.Description.values.tolist())\n",
    "submission_desc_tfidf = tfidf.transform(submission.Description.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "lb_labels = LabelBinarizer()\n",
    "# print y_train[:5]\n",
    "y_train = lb_labels.fit_transform(y_train)\n",
    "y_test = lb_labels.transform(y_test)\n",
    "print lb_labels.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain = hstack([csr_matrix(X_train[cols].astype(float).values), X_train_desc_vec, X_train_desc_tfidf])\n",
    "xtest = hstack([csr_matrix(X_test[cols].astype(float).values), X_test_desc_vec, X_test_desc_tfidf])\n",
    "xsubmission = hstack([csr_matrix(submission[cols].astype(float).values), submission_desc_vec, submission_desc_tfidf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(xtrain, label=y_train)\n",
    "dtest = xgb.DMatrix(xtest, label=y_test)\n",
    "dsubmission = xgb.DMatrix(xsubmission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.206563\ttest-error:0.229452\n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 10 rounds.\n",
      "[10]\ttrain-error:0.186436\ttest-error:0.20797\n",
      "[20]\ttrain-error:0.173133\ttest-error:0.198241\n",
      "[30]\ttrain-error:0.161287\ttest-error:0.188278\n",
      "[40]\ttrain-error:0.150859\ttest-error:0.180806\n",
      "[50]\ttrain-error:0.144725\ttest-error:0.175202\n",
      "[60]\ttrain-error:0.136367\ttest-error:0.170922\n",
      "[70]\ttrain-error:0.130271\ttest-error:0.165862\n",
      "[80]\ttrain-error:0.123869\ttest-error:0.161037\n",
      "[90]\ttrain-error:0.11992\ttest-error:0.1566\n",
      "[100]\ttrain-error:0.114936\ttest-error:0.155044\n",
      "[110]\ttrain-error:0.110106\ttest-error:0.151385\n",
      "[120]\ttrain-error:0.106195\ttest-error:0.14835\n",
      "[130]\ttrain-error:0.103052\ttest-error:0.146482\n",
      "[140]\ttrain-error:0.099141\ttest-error:0.144225\n",
      "[150]\ttrain-error:0.096266\ttest-error:0.14259\n",
      "[160]\ttrain-error:0.093084\ttest-error:0.141267\n",
      "[170]\ttrain-error:0.08971\ttest-error:0.1401\n",
      "[180]\ttrain-error:0.08741\ttest-error:0.138465\n",
      "[190]\ttrain-error:0.084803\ttest-error:0.137765\n",
      "Stopping. Best iteration:\n",
      "[185]\ttrain-error:0.086336\ttest-error:0.13722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {'objective': 'binary:logistic',\n",
    "          'booster': 'gbtree',\n",
    "          'eval_metric': 'error',\n",
    "          'nthread': 4,\n",
    "          'silent': 1,\n",
    "          'max_depth': 6,\n",
    "          'subsample': 0.9,\n",
    "          'min_child_weight': 1,\n",
    "          \"colsample_bytree\": 0.9,\n",
    "          'eta': 0.05,\n",
    "          'seed': 2017}\n",
    "watchlist = [(dtrain, 'train'), (dtest, 'test')]\n",
    "num_rounds = 250\n",
    "clf_xgb = xgb.train(params, dtrain, num_rounds, verbose_eval=10, evals=watchlist, early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.42097336  0.10202809  0.09633233  0.14175852  0.54209566]\n",
      "[[1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      "0.862546699875\n"
     ]
    }
   ],
   "source": [
    "pred = clf_xgb.predict(dtest)\n",
    "print pred[:5]\n",
    "print y_test[:5]\n",
    "pred_ = pred>0.5\n",
    "from sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(y_test, pred_)\n",
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29404L,)\n"
     ]
    }
   ],
   "source": [
    "submit_pred = clf_xgb.predict(dsubmission)\n",
    "print submit_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29404, 2)\n"
     ]
    }
   ],
   "source": [
    "submit_pred = lb_labels.inverse_transform(submit_pred)\n",
    "submit_df = pd.concat([submission_user_id, pd.DataFrame(submit_pred)], axis=1)\n",
    "submit_df.columns = [\"User_ID\", \"Is_Response\"]\n",
    "print submit_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df.head(5)\n",
    "submit_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
